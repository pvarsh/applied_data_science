{
 "metadata": {
  "name": "",
  "signature": "sha256:6c9c1bc8b1a9f76f597fe15186ed39d627f859c8dd1ae5165efcc7e2d1bf413e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets.supervised import SupervisedDataSet \n",
      "from pybrain.tools.shortcuts import buildNetwork\n",
      "from pybrain.supervised.trainers import BackpropTrainer\n",
      "from pybrain.structure import SigmoidLayer\n",
      "from pybrain.structure import SoftmaxLayer\n",
      "\n",
      "import cv2\n",
      "import glob\n",
      "import os\n",
      "import random\n",
      "\n",
      " \n",
      "def loadImage(path):\n",
      "    im = cv2.imread(path)\n",
      "    return flatten(im)\n",
      " \n",
      "def flatten(x):\n",
      "    result = []\n",
      "    for el in x:\n",
      "        if hasattr(el, \"__iter__\") and not isinstance(el, basestring):\n",
      "            result.extend(flatten(el))\n",
      "        else:\n",
      "            result.append(el)\n",
      "    return result\n",
      "\n",
      "def print_f_list(flist, name = \"\"):\n",
      "    print \"\\n### \", name\n",
      "    for f, g1, g2 in flist:\n",
      "        print f.split('/')[-1] \n",
      " \n",
      "if __name__ == \"__main__\":\n",
      "    path_pos = \"/Users/petervarshavsky/Documents/Git_NYU/applied_data_science/lab-2/images/faces/my-face/resized/\"\n",
      "    path_neg = \"/Users/petervarshavsky/Documents/Git_NYU/applied_data_science/lab-2/images/other_faces_resized/\"\n",
      "   \n",
      "    # truth:positive\n",
      "    true_val = (1,0)\n",
      "    false_val = (0,1)\n",
      " \n",
      "    # making training set of positive images\n",
      "    files_pos = [(f, true_val, f.split('/')[-1]) for f in glob.glob(path_pos + \"*.png\")]\n",
      "    random.shuffle(files_pos)\n",
      "    splt = int(len(files_pos) * 2.0/3)\n",
      "    files_pos_train = files_pos[:splt]\n",
      "    files_pos_test  = files_pos[splt:]\n",
      "\n",
      "    # making training set of negative images\n",
      "    files_neg = [(f, false_val, f.split('/')[-1]) for f in glob.glob(path_neg + \"*.png\")]\n",
      "    random.shuffle(files_neg)\n",
      "    splt = int(len(files_neg) * 2.0/3)\n",
      "    files_neg_train = files_neg[:splt]\n",
      "    files_neg_test  = files_neg[splt:]\n",
      "   \n",
      "    print_f_list(files_neg_train, \"files_neg_train\")\n",
      "    print_f_list(files_neg_test, \"files_neg_test\")\n",
      "    print_f_list(files_neg, \"files_neg\")\n",
      " \n",
      "    # putting together training and test sets\n",
      "    train = files_pos_train + files_neg_train\n",
      "    test = files_pos_test + files_neg_test\n",
      "    random.shuffle(train)\n",
      "    random.shuffle(test)\n",
      "    \n",
      "    # first image to start the training set\n",
      "    f, truth, _ = train.pop()\n",
      "    t = loadImage(f)\n",
      "    \n",
      "    # build network\n",
      "    net = buildNetwork(len(t), int(.05*len(t)), int(0.05*len(t)), 2, bias = True, outclass = SoftmaxLayer)\n",
      "   \n",
      "    # initialize data set\n",
      "    ds = SupervisedDataSet(len(t), 2)\n",
      "    ds.addSample(t, truth)\n",
      "    # add the rest of elements to data set\n",
      "    for img, truth in train:\n",
      "        print truth\n",
      "        ds.addSample(loadImage(img), truth)\n",
      "    \n",
      "    # train the network\n",
      "    trainer = BackpropTrainer(net, ds)\n",
      "    error = 1 # was 10\n",
      "    iteration = 0\n",
      "    while error > 0.0001: # was 0.0001 \n",
      "        error = trainer.train()\n",
      "        iteration += 1\n",
      "        print \"Iteration: {0} Error {1}\".format(iteration, error)\n",
      "    \n",
      "    for img, truth in test:\n",
      "        result = net.activate(loadImage(img))\n",
      "        print \"Result (%2.4f, %2.4f): (%2.4f, %2.4f)\" %(truth[0], truth[1], result[0], result[1])\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "###  files_neg_train\n",
        "chaplin-1992--645-75copy.png\n",
        "190copy.png\n",
        "st-vincent-singercopy.png\n",
        "einsteincopy.png\n",
        "Merrill-Garbus-of-Tune-Ya-006copy.png\n",
        "MTE1ODA0OTcxNzI2NjM2NTU3copy.png\n",
        "\n",
        "###  files_neg_test\n",
        "imgrescopy.png\n",
        "groucho2-smcopy.png\n",
        "frank-zappa-05copy.png\n",
        "imagescopy.png\n",
        "\n",
        "###  files_neg\n",
        "chaplin-1992--645-75copy.png\n",
        "190copy.png\n",
        "st-vincent-singercopy.png\n",
        "einsteincopy.png\n",
        "Merrill-Garbus-of-Tune-Ya-006copy.png\n",
        "MTE1ODA0OTcxNzI2NjM2NTU3copy.png\n",
        "imgrescopy.png\n",
        "groucho2-smcopy.png\n",
        "frank-zappa-05copy.png\n",
        "imagescopy.png\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "too many values to unpack",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-ca8e8c2138fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# add the rest of elements to data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}